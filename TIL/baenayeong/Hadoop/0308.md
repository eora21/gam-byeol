# 전문가 멘토링

### 더 생각해봐야 할 것

1. 프로젝트의 목적/주제
2. 누구를 대상으로 하는지
3. 무엇을 개선하고자 하는지
4. 타겟층이 누구인지
5. CAP, 3V에서 더 중요하게 가져가고 싶은 것 추려내기 → 이걸 바탕으로 기술스택 정해야 한다

### 질문과 답변

1. CRUD 기능이 빅데이터 프로젝트로 경쟁력이 있는지, 좀 더 많은 데이터를 가져오는 데 집중해야 하는 게 아닌지
    
    → 같은 CRUD더라도 RDB 기반과 하둡 기반은 다르다. 그리고 외부 데이터에는 한계가 있고 빅데이터가 아니어도 하둡은 적용 가능하기 때문에 괜찮다.
    
2. 하둡에 이미지 파일을 바로 저장하는 게 가능한지
    
    이미지를 바이트 코드로 변환해서 등록하는 방법이 있는 것 보면 가능하긴 할 듯. 다만 속도가 느려지기 때문에 성능적으로는 좋지 않은 방법일 것 같다.
    

# 하둡 공부

## 맵리듀스 알고리즘

- hdfs에 분산 저장되어 있는 데이터를 병렬로 처리해서 취합하는 역할
- **Map Function**
    - key-value의 구조로 되어 있다.
- **Reduce Function**
    - key-(value list)의 구조로 되어 있다.
- job에 대한 구동과 관리는 하둡이 알아서 한다.

### 장점

- 단순하고 사용이 편리하다.
- 특정 데이터 모델이나 스키마, 질의에 의존적이지 않은 유연성 → 플랫폼 내에서 데이터에 관련된 기술을 처리해야 하는 부분들을 알아서 해주기 때문에 비즈니스 로직에만 집중할 수 있다.
- 저장 구조의 독립성
- 데이터를 복제하기 때문에 내구성이 있다.
- 재수행을 통한 내고장성 확보
- 높은 확장성

### 단점

- 고정된 단일 데이터 흐름
- 기존 DBMS보다 스키마 질의가 불편하다.
- 스케줄링이 단순하다.
- 작은 데이터를 저장/처리하기에 적합하지 않다. → 큰 데이터를 빠르게 처리하는 배치 프로그램이어야 적합하다.
- 개발 도구의 불편함
- 기술 지원의 어려움

### 맵리듀스의 구동 방식

- Local
    - 단일 JVM에서 전체 job을 실행하는 방식
- Classic
    - 하둡 버전 1.0까지 유지하던 맵리듀스 분산 처리 방식으로 Job Tracker와 Task Tracker를 사용하는 맵리듀스 버전1
- YARN
    - 하둡 버전 2.0 이상에서 사용하는 맵리듀스 분산 처리 방식으로 맵리듀스 이외의 워크로드 수용이 가능한 맵리듀스 버전2

## 맵리듀스 1.0

### 주요 컴포넌트

- 클라이언트
    - 구현된 맵리듀스 job을 제출하는 실행 주체
- 잡트래커
    - 맵리듀스 job이 수행되는 전체 과정을 조정하며, job에 대한 마스터 역할 수행
- 태스크 트래커
    - job에 대한 분산된 task를 수행하며 실질적인 Data Processing의 주체
- 하둡 분산 파일 시스템
    - 각 단계들 간의 데이터와 처리 과정에서 발생하는 중간 파일들을 공유하기 위해 사용