하이브를 설치하려고 시도해봤는데, 결국 안 된다는 결론이 나왔다.

일단 하이브는 하둡을 기반으로 돌아가는 프로그램이기 때문에 하둡이 설치된 폴더와 같은 폴더에 설치해야 한다. 이걸 하이브 설치 다 하고 설정 파일 수정하다가 알았다. 그래서 하이브 설치를 위해 작성한 것들을 다 삭제해야 했다...

대신 새로운 걸 알았는데 우리에게 주어진 하둡 서버에 이미 spark가 설치되어 있다는 점이었다.

![image](https://user-images.githubusercontent.com/55578809/159762012-ab04ff87-d939-4b43-8b17-6e9e11a98655.png)

&nbsp;

자세한 의미는 모르겠지만 spark 안에 kubernetes, yarn, R 폴더가 있었다. yarn 안에는 spark-3.2.1-yarn-shuffle.jar 파일이 있었는데 이미 spark와 hadoop이 연동이 된 상태로 주어졌던 게 아닐까 싶다. 있는 spark를 활용해서 데이터를 넣을 수 있지 않을지 더 알아봐야겠다.

![image](https://user-images.githubusercontent.com/55578809/159762924-89c05745-bb8f-4803-a51b-4ab35f6e66ec.png)